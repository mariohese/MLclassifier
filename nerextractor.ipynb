{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marioh/anaconda3/lib/python3.6/site-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from preprocessor import preProcessSerie\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, TweetTokenizer, word_tokenize\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "import time\n",
    "#from nltk.tag.corenlp import CoreNLPNERTagger\n",
    "#from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "tknzrwhu = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles = False)\n",
    "\n",
    "st = StanfordNERTagger('/usr/share/stanford-ner-2017-06-09/classifiers/english.all.3class.distsim.crf.ser.gz', \n",
    "                       '/usr/share/stanford-ner-2017-06-09/stanford-ner.jar', \n",
    "                      )\n",
    "\n",
    "def notinlist(item, lista):\n",
    "    booleano = True\n",
    "    if item in lista:\n",
    "        booleano = False\n",
    "    return booleano \n",
    "\n",
    "def allner(dataproc, lista):\n",
    "    ne1 = []\n",
    "    ne2 = []\n",
    "    ne3 = []\n",
    "    sents = sent_tokenize(str(dataproc))\n",
    "    for sent in sents:\n",
    "        lower = []\n",
    "        listwords2 = []\n",
    "        listwords3 = []\n",
    "        listwords = sent.split()\n",
    "        for word in listwords:\n",
    "            listwords2.append(word.capitalize())\n",
    "            listwords3.append(word.upper())\n",
    "            lower.append(word.lower())\n",
    "        ne1.append(lower)\n",
    "        ne2.append(listwords2)\n",
    "        ne3.append(listwords3)\n",
    "            \n",
    "    #ne = [sent.split() for sent in sent_tokenize( str(dataproc) )]\n",
    "    ne_tagged1 = st.tag_sents(ne1)\n",
    "    ne_tagged2 = st.tag_sents(ne2)\n",
    "    ne_tagged3 = st.tag_sents(ne3)\n",
    "    \n",
    "    for s in ne_tagged1:\n",
    "        start_time = time.time()\n",
    "        for i in s:\n",
    "            if (i[1] == 'ORGANIZATION' or i[1] == 'LOCATION' or i[1] == 'PERSON'):\n",
    "                #if notinlist(i, lista):\n",
    "                s = \"\"\n",
    "                l = []\n",
    "                i = list(i)\n",
    "                s = i[0].lower()\n",
    "                l = [s, i[1]]\n",
    "                i = tuple(l)\n",
    "                lista.append(i)\n",
    "\n",
    "                \n",
    "    for s in ne_tagged2:\n",
    "        for i in s:\n",
    "            if (i[1] == 'ORGANIZATION' or i[1] == 'LOCATION' or i[1] == 'PERSON'):\n",
    "                #if notinlist(i, lista):\n",
    "                s = \"\"\n",
    "                l = []\n",
    "                i = list(i)\n",
    "                s = i[0].lower()\n",
    "                l = [s, i[1]]\n",
    "                i = tuple(l)\n",
    "                lista.append(i)\n",
    "                \n",
    "    for s in ne_tagged3:\n",
    "        for i in s:\n",
    "            if (i[1] == 'ORGANIZATION' or i[1] == 'LOCATION' or i[1] == 'PERSON'):\n",
    "                #if notinlist(i, lista):\n",
    "                s = \"\"\n",
    "                l = []\n",
    "                i = list(i)\n",
    "                s = i[0].lower()\n",
    "                l = [s, i[1]]\n",
    "                i = tuple(l)\n",
    "                lista.append(i)\n",
    "                \n",
    "    #print(\"Ha salido, ha tardado:\")\n",
    "    #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return lista\n",
    "\n",
    "def getallner(data):\n",
    "    #fcounter = 20\n",
    "    #scounter = 0\n",
    "    lista = []\n",
    "    listaresultado = []\n",
    "    dataproc = preProcessSerie(data)\n",
    "    #while (fcounter < (17392)):\n",
    "    #    auxlist = []\n",
    "    #    datos = dataproc[scounter:fcounter]\n",
    "    #    auxlist = allner(datos, lista)\n",
    "    #    for i in auxlist:\n",
    "    #        listaresultado.append(i)\n",
    "    #    if fcounter % 500 == 0:\n",
    "    #        print(fcounter)\n",
    "    #    if fcounter < 17380:\n",
    "    #        scounter = scounter + 20\n",
    "    #        fcounter = fcounter + 20\n",
    "    #    else:\n",
    "    #        scounter = scounter + 20\n",
    "    #        fcounter = 17392\n",
    "    lista = allner(dataproc, lista)\n",
    "    return lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ha acabado con los del isis\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "isis = pd.read_csv('isisfanboy.csv')\n",
    "about = pd.read_csv('aboutisis.csv')\n",
    "\n",
    "isis = isis[:17392]\n",
    "about = about[:17392]\n",
    "#El máximo que puedo usar es 17392\n",
    "\n",
    "dataframe = pd.concat([isis, about])\n",
    "X1 = isis['tweets'].values\n",
    "\n",
    "X2 = about['tweets'].values\n",
    "\n",
    "listanerisis = getallner(X1)\n",
    "print(\"Ha acabado con los del isis\")\n",
    "listanerabout = getallner(X2)\n",
    "\n",
    "\n",
    "#pickle.dump(sentimientos, open( \"mcsentiments.p\", \"wb\" ) )\n",
    "\n",
    "#Para cargarlo, luego hacer:    nombrequequeramos = pickle.load( open( \"mcsentiments.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('muhammed', 'ORGANIZATION'), ('us', 'LOCATION'), ('khan', 'PERSON'), ('aqap', 'ORGANIZATION'), ('israel', 'LOCATION'), ('statement', 'ORGANIZATION'), ('fatih', 'PERSON'), ('heat', 'ORGANIZATION'), ('complete', 'ORGANIZATION'), ('medium', 'ORGANIZATION'), ('con', 'ORGANIZATION'), ('saa', 'ORGANIZATION'), ('qui', 'ORGANIZATION'), ('prophet', 'ORGANIZATION'), ('lose', 'ORGANIZATION'), ('word', 'ORGANIZATION'), ('black', 'ORGANIZATION'), ('islamic', 'ORGANIZATION'), ('criminalità', 'ORGANIZATION'), ('için', 'PERSON'), ('tank', 'ORGANIZATION'), ('po...', 'ORGANIZATION'), ('ha', 'PERSON'), ('un', 'ORGANIZATION'), ('sevenler', 'PERSON'), ('kill', 'PERSON'), ('naik', 'PERSON'), ('kerala', 'ORGANIZATION'), ('people', 'ORGANIZATION'), ('carter', 'PERSON'), ('integrity', 'ORGANIZATION'), ('salvation', 'ORGANIZATION'), ('dawlah', 'PERSON'), ('urdu', 'ORGANIZATION'), ('kerala', 'LOCATION'), ('report', 'ORGANIZATION'), ('city', 'LOCATION'), ('isis', 'ORGANIZATION'), ('iraq', 'LOCATION'), ('pentagon', 'ORGANIZATION'), ('kuwaiti', 'ORGANIZATION'), ('bless', 'ORGANIZATION'), ('shakir', 'PERSON'), ('clinto...', 'PERSON'), ('amine', 'PERSON'), ('china', 'LOCATION'), ('gar', 'ORGANIZATION'), ('cool', 'ORGANIZATION'), ('légende', 'ORGANIZATION'), ('pamphlet', 'ORGANIZATION'), ('jawlani', 'PERSON'), ('save', 'ORGANIZATION'), ('subtitle', 'ORGANIZATION'), ('fire', 'ORGANIZATION'), ('aleppo', 'ORGANIZATION'), ('najih', 'PERSON'), ('time', 'ORGANIZATION'), ('use', 'LOCATION'), ('temple', 'LOCATION'), ('create', 'ORGANIZATION'), ('faire', 'ORGANIZATION'), ('hasan', 'ORGANIZATION'), ('hezbollah', 'ORGANIZATION'), ('mosul', 'LOCATION'), ('mount', 'LOCATION'), ('sever', 'LOCATION'), ('syria', 'LOCATION'), ('tribunal', 'ORGANIZATION'), ('decline', 'ORGANIZATION'), ('response', 'ORGANIZATION'), ('base', 'LOCATION'), ('ha', 'ORGANIZATION'), ('isi', 'ORGANIZATION'), ('news', 'ORGANIZATION'), ('irani', 'PERSON'), ('hyderabad', 'LOCATION'), ('tarihi', 'PERSON'), ('combatte', 'ORGANIZATION'), ('isi', 'LOCATION'), ('mustafa', 'PERSON'), ('aslm', 'ORGANIZATION'), ('link', 'ORGANIZATION'), (\"ankara'nın\", 'PERSON'), ('badreddine', 'PERSON'), ('defense', 'ORGANIZATION'), ('raid', 'ORGANIZATION'), ('china', 'ORGANIZATION'), ('gizmodo', 'ORGANIZATION'), ('de', 'ORGANIZATION'), ('russia', 'ORGANIZATION'), ('inshallah', 'ORGANIZATION'), ('traffic', 'ORGANIZATION'), ('al', 'PERSON'), ('exception', 'ORGANIZATION'), ('orta', 'PERSON'), ('fever', 'ORGANIZATION'), ('wuhayshi', 'PERSON'), ('ircg', 'PERSON'), ('le', 'ORGANIZATION'), ('watch', 'ORGANIZATION'), ('il', 'ORGANIZATION'), ('fatih', 'ORGANIZATION'), ('syria', 'ORGANIZATION'), ('subs', 'ORGANIZATION'), ('dawlah', 'ORGANIZATION'), ('palmyra', 'LOCATION'), ('new', 'ORGANIZATION'), ('abu', 'ORGANIZATION'), ('al', 'ORGANIZATION'), ('advice', 'ORGANIZATION'), ('la', 'ORGANIZATION'), ('va', 'ORGANIZATION'), ('irgc', 'ORGANIZATION'), ('tomorrow', 'ORGANIZATION'), ('19', 'ORGANIZATION'), ('recaptured', 'ORGANIZATION'), ('la', 'LOCATION'), ('jawlani', 'ORGANIZATION'), ('une', 'ORGANIZATION'), ('hillary', 'PERSON'), ('video', 'ORGANIZATION'), ('soldier', 'PERSON'), ('pas', 'ORGANIZATION'), ('truthful', 'ORGANIZATION'), ('hassan', 'ORGANIZATION'), ('path', 'ORGANIZATION'), ('message', 'ORGANIZATION'), ('unesco', 'LOCATION'), ('nasir', 'PERSON'), ('ash', 'PERSON'), ('nabi', 'ORGANIZATION'), ('organizzata', 'ORGANIZATION'), ('hell', 'ORGANIZATION'), ('plunge', 'ORGANIZATION'), ('terrorist', 'ORGANIZATION'), ('rejoint', 'ORGANIZATION'), ('group', 'ORGANIZATION'), ('eng', 'ORGANIZATION'), ('retake', 'LOCATION'), ('si', 'ORGANIZATION'), ('download', 'ORGANIZATION'), ('sheikh', 'ORGANIZATION'), ('c', 'ORGANIZATION'), ('cúpula', 'ORGANIZATION'), ('say', 'ORGANIZATION'), ('international', 'ORGANIZATION'), ('#jn', 'ORGANIZATION'), ('influence', 'ORGANIZATION'), ('france', 'ORGANIZATION'), ('tie', 'LOCATION'), ('zakir', 'PERSON'), ('#is', 'ORGANIZATION'), ('state', 'ORGANIZATION'), ('eser', 'PERSON'), ('unesco', 'ORGANIZATION'), ('syrian', 'ORGANIZATION'), ('twitter', 'ORGANIZATION'), ('daesh', 'ORGANIZATION'), ('water', 'ORGANIZATION'), ('regard', 'ORGANIZATION'), ('release', 'ORGANIZATION')]\n"
     ]
    }
   ],
   "source": [
    "listaner = listanerisis + listanerabout\n",
    "listaner = list(set(listaner))\n",
    "\n",
    "print(listaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(listaner, open( \"ner.p\", \"wb\" ) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
